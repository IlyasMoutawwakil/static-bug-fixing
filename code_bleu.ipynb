{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bleu\n",
    "import weighted_ngram_match\n",
    "import syntax_match\n",
    "import dataflow_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram match: 0.6075256576979613, weighted ngram match: 0.6367970871812899, syntax_match: 0.7851239669421488, dataflow_match: 0.7192982456140351\n",
      "CodeBLEU score:  0.6871862393588588\n"
     ]
    }
   ],
   "source": [
    "# preprocess inputs\n",
    "lang = 'java'\n",
    "alpha, beta, gamma, theta = [0.25, 0.25, 0.25, 0.25]\n",
    "pre_references = [[x.strip() for x in open(file, 'r', encoding='utf-8').readlines()]\n",
    "                  for file in ['data/references.txt']]\n",
    "hypothesis = [x.strip()\n",
    "              for x in open('data/predictions.txt', 'r', encoding='utf-8').readlines()]\n",
    "\n",
    "for i in range(len(pre_references)):\n",
    "    assert len(hypothesis) == len(pre_references[i])\n",
    "\n",
    "references = []\n",
    "for i in range(len(hypothesis)):\n",
    "    ref_for_instance = []\n",
    "    for j in range(len(pre_references)):\n",
    "        ref_for_instance.append(pre_references[j][i])\n",
    "    references.append(ref_for_instance)\n",
    "assert len(references) == len(pre_references)*len(hypothesis)\n",
    "\n",
    "\n",
    "# calculate ngram match (BLEU)\n",
    "tokenized_hyps = [x.split() for x in hypothesis]\n",
    "tokenized_refs = [[x.split() for x in reference] for reference in references]\n",
    "\n",
    "ngram_match_score = bleu.corpus_bleu(tokenized_refs, tokenized_hyps)\n",
    "\n",
    "# calculate weighted ngram match\n",
    "keywords = [x.strip() for x in open(\n",
    "    f'data/{lang}-keywords.txt', 'r', encoding='utf-8').readlines()]\n",
    "\n",
    "\n",
    "def make_weights(reference_tokens, key_word_list):\n",
    "    return {token: 1 if token in key_word_list else 0.2\n",
    "            for token in reference_tokens}\n",
    "\n",
    "\n",
    "tokenized_refs_with_weights = [[[reference_tokens, make_weights(reference_tokens, keywords)]\n",
    "                                for reference_tokens in reference] for reference in tokenized_refs]\n",
    "\n",
    "weighted_ngram_match_score = weighted_ngram_match.corpus_bleu(\n",
    "    tokenized_refs_with_weights, tokenized_hyps)\n",
    "\n",
    "# calculate syntax match\n",
    "syntax_match_score = syntax_match.corpus_syntax_match(\n",
    "    references, hypothesis, lang)\n",
    "\n",
    "# calculate dataflow match\n",
    "dataflow_match_score = dataflow_match.corpus_dataflow_match(\n",
    "    references, hypothesis, lang)\n",
    "\n",
    "print('ngram match: {0}, weighted ngram match: {1}, syntax_match: {2}, dataflow_match: {3}'.\n",
    "      format(ngram_match_score, weighted_ngram_match_score, syntax_match_score, dataflow_match_score))\n",
    "\n",
    "code_bleu_score = alpha*ngram_match_score\\\n",
    "    + beta*weighted_ngram_match_score\\\n",
    "    + gamma*syntax_match_score\\\n",
    "    + theta*dataflow_match_score\n",
    "\n",
    "print('CodeBLEU score: ', code_bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "static-bug-fixing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d713b843a73b127a159455cd0c796efca24dd1d016ba991f0bfdc602988835f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
